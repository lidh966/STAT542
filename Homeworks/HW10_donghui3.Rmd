---
title: 'STAT 542: Homework 10'
author: "FALL 2020, by Donghui Li (donghui3)"
date: 'Due: Monday, Nov 16, 11:59 PM CT'
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
  knitr::opts_chunk$set(include = TRUE)  # TRUE for solution; FALSE for questions set
  knitr::opts_chunk$set(echo = TRUE)
  knitr::opts_chunk$set(cache = TRUE)
  knitr::opts_chunk$set(message = FALSE)
  knitr::opts_chunk$set(warning = FALSE)
  knitr::opts_chunk$set(fig.height = 6, fig.width = 8, out.width = '80%', fig.align = "center")
  options(width = 90)
```

```{css, echo=FALSE}
.solution {
background-color: #e6ffe6;
}
```

## About HW10

This homework involves two coding questions. One is discriminant analysis, and another one for linear separable SVM. Non-separable and nonlinear SVM questions will be in the next HW. 

## Question 1 [50 Points] Discriminant Analysis

For this question, you need to write your own code. We will use the handwritten digit recognition data again from the `ElemStatLearn` package. We only consider the train-test split, with the pre-defined `zip.train` and `zip.test`, and no cross-validation is needed. Simply use `zip.train` as the training data, and `zip.test` as the testing data for any evaluation and tuning. 

### a) [25 points] Linear discriminate analysis

Write your own linear discriminate analysis (LDA) code following our lecture note. Use the training data to estimate all parameters and apply them to the testing data to evaluate the performance. Report the model fitting results (such as a confusion table and misclassification rates). Which digit seems to get misclassified the most?

### Answer
The code and results are shown below. We can observe that the digit 5 is misclassified the most.
```{r}
library(ElemStatLearn)

train = zip.train
test = zip.test
n = nrow(train)
p = ncol(train)-1

z = as.data.frame(train)
groups = split(z, z$V1)    # each list item is a matrix of class k
K = length(groups)

# calculate class static for class k
mu_hat = list()
pi_hat = list()
for (k in 1:K) {
  mu_hat[[k]] = as.matrix(colMeans(groups[[k]][, 2:(p+1)]))
  pi_hat[[k]] = nrow(groups[[k]]) / n
}

sigma_hat = matrix(0, p, p)
for (k in 1:K) {
  X0 = groups[[k]][,2:(p+1)]
  for (i in 1:nrow(X0)) {
    mu0 = as.matrix(mu_hat[[k]])
    xi = t(as.matrix(X0[i,]))
    sigma_k = (xi-mu0) %*% t(xi-mu0)
    sigma_hat = sigma_hat + sigma_k
  }
}
sigma_hat = 1/(n-K) * sigma_hat

# loop in test data
test_new = as.data.frame(test)
test_new$label = integer(length=nrow(test))
for (i in 1:nrow(test)) {
  xi_test = as.matrix(test[i, 2:(p+1)])
  f_list = list()
  for (k in 1:K) {
    f = -1/2 * t(xi_test - mu_hat[[k]]) %*% chol2inv(chol(sigma_hat)) %*% (xi_test - mu_hat[[k]]) + log(pi_hat[[k]])
    f_list[[k]] = f
  }
  label = which.max(unlist(f_list)) - 1
  test_new$label[i] = label
}

compare = as.data.frame(cbind(test_new$V1, test_new$label))
compare$result = logical(length = nrow(compare))
compare$result = compare$V1 == compare$V2
# misclassification rate
mr = 1 - sum(compare$result) / nrow(compare)    # overall misclassification rates
mr_list = c()    # misclassification rate for each class
for (k in 1:K) {
  x = compare[compare$V1 == (k-1), ]
  mr_list = c(mr_list, 1 - sum(x$result) / nrow(x))
}

print(paste("The misclassification rate over the entire test set is", mr))
print("The misclassification rate for each class from 0-9 is:")
print(mr_list)
print(paste("The digit mostly misclassfied is", which.max(mr_list)-1))
```



### b) [25 points] Regularized quadratic discriminate analysis

QDA does not work directly in this example because we do not have enough samples to provide an invertible sample covariance matrix. An alternative idea to fix this issue is to consider a regularized QDA method, which uses 
$$\widehat \Sigma_k(\alpha) = \alpha \widehat \Sigma_k + (1-\alpha) \widehat \Sigma $$
for some $\alpha \in (0, 1)$. Here $\widehat \Sigma$ is the estimatior from the LDA method. Implement this method and select the best tuning parameter (on a grid) based on the testing error. You should again report the model fitting results similar to the previous part. What is your best tuning parameter, and what does that imply in terms of the underlying data and the performance of the model? 

### Answer

The code and results are shown below:
```{r}
library(ElemStatLearn)

train = zip.train
test = zip.test
n = nrow(train)
p = ncol(train)-1

z = as.data.frame(train)
groups = split(z, z$V1)    # each list item is a matrix of class k
K = length(groups)

# calculate class static for class k
mu_hat = list()
pi_hat = list()
for (k in 1:K) {
  mu_hat[[k]] = as.matrix(colMeans(groups[[k]][, 2:(p+1)]))
  pi_hat[[k]] = nrow(groups[[k]]) / n
}

sigma_class = list()
sigma_hat = matrix(0, p, p)
for (k in 1:K) {
  X0 = groups[[k]][,2:(p+1)]
  sigma_class_k = matrix(0, p, p)
  for (i in 1:nrow(X0)) {
    mu0 = as.matrix(mu_hat[[k]])
    xi = t(as.matrix(X0[i,]))
    sigma_k = (xi-mu0) %*% t(xi-mu0)
    sigma_class_k = sigma_class_k + sigma_k
    sigma_hat = sigma_hat + sigma_k
  }
  sigma_class[[k]] = 1/(nrow(groups[[k]])-1) * sigma_class_k
}
sigma_hat = 1/(n-K) * sigma_hat


alpha_seq = seq(0, 0.1, by=0.01)
mr_vec = c()
compare_list = list()
for (alpha in alpha_seq) {
  sigma_class_new = list()    # regularized covariance
  for (k in 1:K) {
    sigma_class_new[[k]] = alpha * sigma_class[[k]] + (1-alpha) * sigma_hat
  }
  
  # loop in test data
  test_new = as.data.frame(test)
  test_new$label = integer(length=nrow(test))
  for (i in 1:nrow(test)) {
    xi_test = as.matrix(test[i, 2:(p+1)])
    f_list = list()
    for (k in 1:K) {
      f = -1/2 * t(xi_test - mu_hat[[k]]) %*% chol2inv(chol(sigma_class_new[[k]])) %*% (xi_test - mu_hat[[k]]) + log(pi_hat[[k]]) -1/2 * log(det(sigma_class_new[[k]]))
      f_list[[k]] = f
    }
    label = which.max(unlist(f_list)) - 1
    test_new$label[i] = label
  }
  
  compare = as.data.frame(cbind(test_new$V1, test_new$label))
  compare$result = logical(length = nrow(compare))
  compare$result = compare$V1 == compare$V2
  compare_list[[length(compare_list)+1]] = compare
  mr = 1 - sum(compare$result) / nrow(compare)    # overall misclassification rates
  mr_vec = c(mr_vec, mr)
}

plot(alpha_seq, mr_vec, xlab = "alpha", ylab = "misclassification rate")
```
By plotting the misclassification rate against the alpha value, I pick up $\alpha=0.04$ as the best tuning parameter.
The model report is as follows:
```{r}
compare = compare_list[[5]]
# misclassification rate
mr = 1 - sum(compare$result) / nrow(compare)    # overall misclassification rates
mr_list = c()    # misclassification rate for each class
for (k in 1:K) {
  x = compare[compare$V1 == (k-1), ]
  mr_list = c(mr_list, 1 - sum(x$result) / nrow(x))
}

print(paste("The misclassification rate over the entire test set is", mr))
print("The misclassification rate for each class from 0-9 is:")
print(mr_list)
print(paste("The digit mostly misclassfied is", which.max(mr_list)-1))
```


## Question 2 [40 Points] Sovling SVM using Quadratic Programming

Install the `quadprog` package (there are similar ones in Python too) and utilize the function `solve.QP` to solve SVM. The `solve.QP` function is trying to perform the minimization problem:
\begin{align}
\text{minimize} & \quad \frac{1}{2} \boldsymbol\beta^T \mathbf{D} \boldsymbol\beta - d^T \boldsymbol\beta \nonumber \\
\text{subject to} & \quad \mathbf{A}^T \boldsymbol\beta \geq a \nonumber
\end{align}
For more details, read the document file of the \texttt{quadprog} package on CRAN. You should generate the data using the following code (or write a similar code in Python). For each sub-question, perform the following: 

  * Properly define $\mathbf{D}$, $d$, $A$ and $a$.
  * Convert the solution into $\beta$ and $\beta_0$, which can be used to define the classification rule
  * Plot the decision line, the two margin lines and the support vectors

__Note__: The package requires $\mathbf{D}$ to be positive definite, while it may not be true in our case. A workaround is to add a "ridge," e.g., $10^{-5} \mathbf{I}$, to the $\mathbf{D}$ matrix, making it invertible. This may affect your results slightly. So be careful when plotting your support vectors. 

```{r fig.width=6, fig.height=6, out.width = '50%', fig.align = "center"}
  set.seed(3); n <-40; p <- 2
  xpos <- matrix(rnorm(n*p, mean=0, sd=1), n, p)
  xneg <- matrix(rnorm(n*p, mean=4, sd=1), n, p)
  x <- rbind(xpos, xneg)
  y <- matrix(c(rep(1, n), rep(-1, n)))
  
  plot(x,col=ifelse(y>0,"darkorange", "deepskyblue"), pch = 19, xlab = "x1", ylab = "x2")
  legend("topleft", c("Positive","Negative"), 
       col=c("darkorange", "deepskyblue"), pch=c(19, 19), text.col=c("darkorange", "deepskyblue"))
```

### a) [25 points] Primal Form

Formulate the SVM __primal__ problem of the separable SVM formulation and obtain the solution to the above question. 

### Answer
Primal problem:
$$
\begin{aligned}
&~ \min_{\boldsymbol \beta, \beta_0} \frac{1}{2} || \boldsymbol \beta || ^2 \\
s.t. \hspace{0.5cm} &~ y_i x_i^T \boldsymbol \beta \geq 1, i=1,2,...,n
\end{aligned}
$$

The code and results are shown below:
```{r}
set.seed(3); n <-40; p <- 2
xpos <- matrix(rnorm(n*p, mean=0, sd=1), n, p)
xneg <- matrix(rnorm(n*p, mean=4, sd=1), n, p)
x <- rbind(xpos, xneg)
y <- matrix(c(rep(1, n), rep(-1, n)))



library(quadprog)

y1 = y[1]
x1 = as.matrix(x[1,])
At = y1 * t(x1)
for (i in 2:nrow(x)) {
  At = rbind(At, y[i]*t(as.matrix(x[i,])))
}
At = cbind(At, y)
D = matrix(c(1,0,0,0,1,0,0,0,0), 3, 3)
d = matrix(0, 3, 1)
a = matrix(1, nrow(y), 1)

D = D + 10^(-10) * diag(1, nrow(D), ncol(D))
result = solve.QP(D, d, t(At), a)

beta = result$solution
plot(x,col=ifelse(y>0,"darkorange", "deepskyblue"), pch = 19, xlab = "x1", ylab = "x2")
legend("topleft", c("Positive","Negative"), 
       col=c("darkorange", "deepskyblue"), pch=c(19, 19), text.col=c("darkorange", "deepskyblue"))
abline(-beta[3]/beta[2], -beta[1]/beta[2], lty=1, lwd = 2)
abline(a=(-beta[3]-1)/beta[2], b=-beta[1]/beta[2], col="black", lty=3, lwd = 2)
abline(a=(-beta[3]+1)/beta[2], b=-beta[1]/beta[2], col="black", lty=3, lwd = 2)
```

### b) [25 points] Dual Form

Formulate the SVM __dual__ problem of the separable SVM formulation and obtain the solution to the above question. 

### Answer
The dual problem is:
$$
\begin{aligned}
&~\min_{\alpha_i} \frac{1}{2} \sum_{i,j=1}^n y_i y_j \alpha_i \alpha_j x_i^T x_j - \sum_{i=1}^n \alpha_i  \\
s.t. \hspace{0.5cm} &~ \alpha_i \geq 1, i=1,2,...,n  \\
&~ \sum_{i=1}^n \alpha_i y_i = 0
\end{aligned}
$$
The code and results are shown below:
```{r}
DD = as.matrix(as.vector(y)*x)
D = DD %*% t(DD)
At = diag(1, nrow(x))
At = rbind(as.vector(y), At)

d = matrix(1, nrow(x))
a = matrix(0, nrow(x)+1, 1)
D = D + 10^(-10) * diag(1, nrow(D), ncol(D))
result = solve.QP(D, d, t(At), a, meq=1)
alpha = result$solution

beta_hat = c(0,0)
for (i in 1:nrow(x)) {
  beta_hat = beta_hat + alpha[i] * y[i] * x[i,]
}

# calculate beta0
sum_pos = c()
sum_neg = c()
for (i in 1:nrow(xpos)) {
  sum_pos = c(sum_pos, t(as.matrix(xpos[i,])) %*% as.matrix(beta_hat))
}
for (i in 1:nrow(xneg)) {
  sum_neg = c(sum_neg, t(as.matrix(xneg[i,])) %*% as.matrix(beta_hat))
}
beta0_hat = 1/2 * (max(sum_neg) + min(sum_pos))

plot.new()
plot(x,col=ifelse(y>0,"darkorange", "deepskyblue"), pch = 19, xlab = "x1", ylab = "x2")
legend("topleft", c("Positive","Negative"), 
       col=c("darkorange", "deepskyblue"), pch=c(19, 19), text.col=c("darkorange", "deepskyblue"))
abline(beta0_hat/beta_hat[2], -beta_hat[1]/beta_hat[2], lty=1, lwd = 2)
abline(a=(beta0_hat-1)/beta_hat[2], b=-beta_hat[1]/beta_hat[2], col="black", lty=3, lwd = 2)
abline(a=(beta0_hat+1)/beta_hat[2], b=-beta_hat[1]/beta_hat[2], col="black", lty=3, lwd = 2)
```







